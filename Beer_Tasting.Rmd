---
title: "Beer_Tasting_21"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd(".")
```

## R Markdown

A slew of many many different beers - all of them for us to try! What Breweries do we have represented? 
1. Brassneck 
2. Strange Fellows
3. R & B 
4. Faculty 
5. Storm 
6. Main Street 

```{r echo = F , warning = F}
library(readxl)
library(dplyr)
library(tidyverse)
library(cowplot)
library(RColorBrewer)
library(tm); library(SnowballC); library(wordcloud); library(RCurl); library(XML)
beers <- read_excel("C:/Users/ssmithtr/Desktop/Sync/Beer_Tasting_Retreat_21.xlsx")
beers <- read_excel("Beer_Tasting_Retreat_21.xlsx")
type_count <- beers %>% count(Type)


#++++++++++++++++++++++++++++++++++
# rquery.wordcloud() : Word cloud generator
# - http://www.sthda.com
#+++++++++++++++++++++++++++++++++++
# x : character string (plain text, web url, txt file path)
# type : specify whether x is a plain text, a web page url or a file path
# lang : the language of the text
# excludeWords : a vector of words to exclude from the text
# textStemming : reduces words to their root form
# colorPalette : the name of color palette taken from RColorBrewer package, 
  # or a color name, or a color code
# min.freq : words with frequency below min.freq will not be plotted
# max.words : Maximum number of words to be plotted. least frequent terms dropped
# value returned by the function : a list(tdm, freqTable)
rquery.wordcloud <- function(x, type=c("text", "url", "file"), 
                          lang="english", excludeWords=NULL, 
                          textStemming=FALSE,  colorPalette="Dark2",
                          min.freq=2, max.words=200)
{ 
  library("tm")
  library("SnowballC")
  library("wordcloud")
  library("RColorBrewer") 
  
  if(type[1]=="file") text <- readLines(x)
  else if(type[1]=="url") text <- html_to_text(x)
  else if(type[1]=="text") text <- x
  
  # Load the text as a corpus
  docs <- Corpus(VectorSource(text))
  # Convert the text to lower case
  docs <- tm_map(docs, content_transformer(tolower))
  # Remove numbers
  docs <- tm_map(docs, removeNumbers)
  # Remove stopwords for the language 
  docs <- tm_map(docs, removeWords, stopwords(lang))
  # Remove punctuations
  docs <- tm_map(docs, removePunctuation)
  # Eliminate extra white spaces
  docs <- tm_map(docs, stripWhitespace)
  # Remove your own stopwords
  if(!is.null(excludeWords)) 
    docs <- tm_map(docs, removeWords, excludeWords) 
  # Text stemming
  if(textStemming) docs <- tm_map(docs, stemDocument)
  # Create term-document matrix
  tdm <- TermDocumentMatrix(docs)
  m <- as.matrix(tdm)
  v <- sort(rowSums(m),decreasing=TRUE)
  d <- data.frame(word = names(v),freq=v)
  # check the color palette name 
  if(!colorPalette %in% rownames(brewer.pal.info)) colors = colorPalette
  else colors = brewer.pal(8, colorPalette) 
  # Plot the word cloud
  set.seed(1234)
  wordcloud(d$word,d$freq, min.freq=min.freq, max.words=max.words,
            random.order=FALSE, rot.per=0.35, 
            use.r.layout=FALSE, colors=colors)
  
  invisible(list(tdm=tdm, freqTable = d))
}

```


```{r pressure, echo=FALSE, warning=F}

bp <- ggplot(type_count, aes(x = "", y = n, group = Type)) + geom_bar(aes(color = Type, fill = Type),stat = "identity") + scale_color_brewer(type = "qual", palette = "Paired") + scale_fill_brewer(type = "qual", 
                                                                                                                                                                                                    palette = "Paired") + theme_minimal(base_size = 24) + ylab("Number of Beers") + 
  xlab("") 
bp
  
```
Now let's look at what flavors we can expect today - 
no surprise since we have a lot of pale ales we have a number of citrus notes to keep out eyes out for! 

```{r, echo = F}
notes <- unlist(strsplit(as.character(beers$`Key notes`), ','))
rquery.wordcloud(notes, type=c("text"), 
        lang="english", excludeWords = NULL, 
        textStemming = FALSE,  colorPalette="Dark2",
        max.words=200)

```

